{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An autoencoder Consists of 3 parts:\n",
    "    1. Encoder\n",
    "    2. Bottleneck\n",
    "    3. Decoder\n",
    "    \n",
    "Encoder/Decoder are fully connected feed foward neural networks\n",
    "and the bottleneck is \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import datasets\n",
    "\n",
    "\n",
    "#torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "tensor_transform = transforms.ToTensor()\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device:',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"~/torch_datasets\", train=True, transform=transform, download=True\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"~/torch_datasets\", train=False, transform=transform, download=True\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=256, shuffle=True, num_workers=0, pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=32, shuffle=False, num_workers=0\n",
    ")\n",
    "\n",
    "example_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=1, shuffle=True, num_workers=0,drop_last=True,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions\n",
    "def plot():\n",
    "    f, axarr = plt.subplots(2)\n",
    "\n",
    "    for i, item in enumerate(image):\n",
    "    # Reshape the array for plotting\n",
    "        item = item.reshape(-1, 28, 28)\n",
    "        axarr[0].imshow(item[0].cpu())\n",
    "\n",
    "    for i, item in enumerate(reconstructed):\n",
    "        item = item.reshape(-1, 28, 28).cpu()\n",
    "        item = item.detach().numpy()\n",
    "        axarr[1].imshow(item[0])\n",
    "        \n",
    "        \n",
    "        \n",
    "def showExample():\n",
    "    for image, _ in example_loader:\n",
    "        f, axarr = plt.subplots(2)\n",
    "        image = image.reshape(-1,28*28).to(device)\n",
    "\n",
    "        model.to(device)\n",
    "        recon = model(image)\n",
    "\n",
    "        image = image.reshape(-1, 28, 28)\n",
    "        axarr[0].imshow(image[0].cpu())\n",
    "\n",
    "\n",
    "        recon = recon.reshape(-1, 28, 28).to('cpu')\n",
    "        axarr[1].imshow(recon[0].detach().numpy())\n",
    "\n",
    "        break\n",
    "\n",
    "def add_noise(inputs,variance):\n",
    "    noise = torch.randn_like(inputs)\n",
    "    return inputs + variance*noise\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pin_memory = true allowsto speed up training when we load to cpu then push to gpu \n",
    "(Lets you allocate sampl es in page-locked memory, should be enabled when training on gpu )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets.MNIST()\n",
    "from torchvision import datasets \n",
    "\n",
    "dataset = datasets.MNIST(root = \"./data\",\n",
    "                         train = True,\n",
    "                         download = True,\n",
    "                         transform = tensor_transform)\n",
    "\n",
    "\n",
    " \n",
    "loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                     batch_size=12,\n",
    "                                     shuffle= True,\n",
    "                                     generator=torch.Generator(device=device))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will be constructing the encoder and decoder, 2 fully connected, feed forward Neural networks  \n",
    "\n",
    "Encoder will gradually reduce dimentionality  \n",
    "28*28=784 -> 128 -> 64 -> 36 -> 18 -> 9\n",
    "  \n",
    "Decoder will do the opposite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28*28  #784\n",
    "hidden_size = 128\n",
    "code_size = 32\n",
    "\n",
    "\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        #Encoder \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size,hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size,code_size)\n",
    "        )\n",
    "        \n",
    "        #Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(code_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, input_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.model = nn.Sequential(\n",
    "        \n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model Initialization\n",
    "model = autoencoder()\n",
    "model.to(device)\n",
    " \n",
    "# Validation using MSE Loss function\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "#Adam Optimizer with lr = 0.1\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model for 20 epoch:\n",
    "Things to notice:\n",
    "- Firstly we are setting to zero gradient before each backpropagation\n",
    "    because pytorch accumulates the gradients on subsequent backward losses\n",
    "    (this may be usefull when training RNNs)\n",
    "- then we are passing the image through the model and calculate loss with a simple MSE Loss$$ (x - g(f(x)))^{2} $$\n",
    "\n",
    "- loss.backward() computes loss and we are preforming backpropagation with optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/20, loss = 0.078962\n",
      "epoch : 2/20, loss = 0.063996\n",
      "epoch : 3/20, loss = 0.059649\n",
      "epoch : 4/20, loss = 0.055144\n",
      "epoch : 5/20, loss = 0.054459\n",
      "epoch : 6/20, loss = 0.051476\n",
      "epoch : 7/20, loss = 0.052486\n",
      "epoch : 8/20, loss = 0.050170\n",
      "epoch : 9/20, loss = 0.050821\n",
      "epoch : 10/20, loss = 0.049526\n",
      "epoch : 11/20, loss = 0.049144\n",
      "epoch : 12/20, loss = 0.048658\n",
      "epoch : 13/20, loss = 0.049471\n",
      "epoch : 14/20, loss = 0.048885\n",
      "epoch : 15/20, loss = 0.047948\n",
      "epoch : 16/20, loss = 0.048412\n",
      "epoch : 17/20, loss = 0.048767\n",
      "epoch : 18/20, loss = 0.048325\n",
      "epoch : 19/20, loss = 0.047167\n",
      "epoch : 20/20, loss = 0.047014\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "losses = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for image, _ in train_loader:\n",
    "        image = image.reshape(-1,28*28).to(device)\n",
    "        noised_image = add_noise(image,0.2)\n",
    "        #set gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        reconstructed = model(noised_image)\n",
    "        loss = loss_function(reconstructed , noised_image)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "    losses = losses / len(train_loader)\n",
    "    print(\"epoch : {}/{}, loss = {:.6f}\".format(epoch + 1, epochs, loss))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "showExample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "for image, _ in example_loader:\n",
    "    \n",
    "    \n",
    "    f, axarr = plt.subplots(2)\n",
    "    image = image.reshape(-1,28*28).to(device)\n",
    "\n",
    "    \n",
    "    #image = add_noise(image,0.5)\n",
    "    model.to(device)\n",
    "    recon = model(image)\n",
    "    image = image.reshape(-1, 28, 28)\n",
    "   \n",
    "    axarr[0].imshow(image[0].cpu())\n",
    "    \n",
    "\n",
    "    \n",
    "    recon = recon.reshape(-1, 28, 28).to('cpu')\n",
    "    axarr[1].imshow(recon[0].detach().numpy())\n",
    "\n",
    "    break    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "0747f93ff6db21b2db2bf35ad4858dd0825b9c21797c41b4cc32097944ab3f10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
