{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An autoencoder Consists of 3 parts:\n",
    "    1. Encoder\n",
    "    2. Bottleneck\n",
    "    3. Decoder\n",
    "    \n",
    "Encoder/Decoder are fully connected feed foward neural networks\n",
    "and the bottleneck is \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import datasets\n",
    "\n",
    "\n",
    "#torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "tensor_transform = transforms.ToTensor()\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device:',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% train data\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"~/torch_datasets\", train=True, transform=transform, download=True\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"~/torch_datasets\", train=False, transform=transform, download=True\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=256, shuffle=True, num_workers=0, pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=32, shuffle=False, num_workers=0\n",
    ")\n",
    "\n",
    "example_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=1, shuffle=True, num_workers=0,drop_last=True,\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    transforms.Resize((300,300))\n",
    "    ])\n",
    "\n",
    "flowers_train_dataset = torchvision.datasets.Flowers102(\n",
    "    root=\"~/torch_datasets\",split=\"train\",transform=flower_transform,download=True)\n",
    "\n",
    "flower_loader = torch.utils.data.DataLoader(\n",
    "    flowers_train_dataset, batch_size=256, shuffle=True, num_workers=0, pin_memory=True\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions\n",
    "def plot():\n",
    "    f, axarr = plt.subplots(2)\n",
    "\n",
    "    for i, item in enumerate(image):\n",
    "    # Reshape the array for plotting\n",
    "        item = item.reshape(-1, 28, 28)\n",
    "        axarr[0].imshow(item[0].cpu())\n",
    "\n",
    "    for i, item in enumerate(reconstructed):\n",
    "        item = item.reshape(-1, 28, 28).cpu()\n",
    "        item = item.detach().numpy()\n",
    "        axarr[1].imshow(item[0])\n",
    "        \n",
    "        \n",
    "        \n",
    "def showExample():\n",
    "    for image, _ in example_loader:\n",
    "        f, axarr = plt.subplots(2)\n",
    "        image = image.reshape(-1,28*28).to(device)\n",
    "\n",
    "        model.to(device)\n",
    "        recon = model(image)\n",
    "\n",
    "        image = image.reshape(-1, 28, 28)\n",
    "        axarr[0].imshow(image[0].cpu())\n",
    "\n",
    "\n",
    "        recon = recon.reshape(-1, 28, 28).to('cpu')\n",
    "        axarr[1].imshow(recon[0].detach().numpy())\n",
    "\n",
    "        break\n",
    "\n",
    "def add_noise(inputs,variance):\n",
    "    noise = torch.randn_like(inputs)\n",
    "    return inputs + variance*noise\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pin_memory = true allowsto speed up training when we load to cpu then push to gpu \n",
    "(Lets you allocate sampl es in page-locked memory, should be enabled when training on gpu )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets.MNIST()\n",
    "from torchvision import datasets \n",
    "\n",
    "dataset = datasets.MNIST(root = \"./data\",\n",
    "                         train = True,\n",
    "                         download = True,\n",
    "                         transform = tensor_transform)\n",
    "\n",
    "\n",
    " \n",
    "loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                     batch_size=12,\n",
    "                                     shuffle= True,\n",
    "                                     generator=torch.Generator(device=device))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will be constructing the encoder and decoder, 2 fully connected, feed forward Neural networks  \n",
    "\n",
    "Encoder will gradually reduce dimentionality  \n",
    "28*28=784 -> 128 -> 64 -> 36 -> 18 -> 9\n",
    "  \n",
    "Decoder will do the opposite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28*28  #784\n",
    "hidden_size = 128\n",
    "code_size = 32\n",
    "\n",
    "\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        #Encoder \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size,hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size,code_size)\n",
    "        )\n",
    "        \n",
    "        #Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(code_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, input_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.model = nn.Sequential(\n",
    "        \n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model Initialization\n",
    "model = autoencoder()\n",
    "model.to(device)\n",
    " \n",
    "# Validation using MSE Loss function\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "#Adam Optimizer with lr = 0.1\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model for 20 epoch:\n",
    "Things to notice:\n",
    "- Firstly we are setting to zero gradient before each backpropagation\n",
    "    because pytorch accumulates the gradients on subsequent backward losses\n",
    "    (this may be usefull when training RNNs)\n",
    "- then we are passing the image through the model and calculate loss with a simple MSE Loss$$ (x - g(f(x)))^{2} $$\n",
    "\n",
    "- loss.backward() computes loss and we are preforming backpropagation with optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "losses = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for image, _ in train_loader:\n",
    "        image = image.reshape(-1,28*28).to(device)\n",
    "        noised_image = add_noise(image,0.2)\n",
    "        #set gradients to zero\n",
    "        \n",
    "        reconstructed = model(noised_image)\n",
    "        loss = loss_function(reconstructed , noised_image)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # Preforms Backpropagation and calculates  gradients \n",
    "        optimizer.step() # Updates Weights based on the gradients computed above\n",
    "        losses += loss.item()\n",
    "    losses = losses / len(train_loader)\n",
    "    print(\"epoch : {}/{}, loss = {:.6f}\".format(epoch + 1, epochs, loss))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showExample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for image, _ in train_loader:\n",
    "    #example = torch.movedim(image[0],(1,2),(0,1))\n",
    "   \n",
    "    f, axarr = plt.subplots(2)\n",
    "    image = image.reshape(-1,28*28).to(device)\n",
    "    \n",
    "    image = add_noise(image,0.0)\n",
    "    model.to(device)\n",
    "    recon = model(image)\n",
    "    image = image.reshape(-1, 28, 28)\n",
    "   \n",
    "    axarr[0].imshow(image[0].cpu())\n",
    "    \n",
    "\n",
    "    \n",
    "    recon = recon.reshape(-1, 28, 28).to('cpu')\n",
    "    #example = torch.movedim(example,(0,1,2),(-1,-2,-3))\n",
    "    axarr[1].imshow(recon[0].detach().numpy())\n",
    "\n",
    "    break    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "0747f93ff6db21b2db2bf35ad4858dd0825b9c21797c41b4cc32097944ab3f10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
